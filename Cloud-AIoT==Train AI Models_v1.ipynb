{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Initialize Cloud-AI Engine__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Install/Verify Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install - -upgrade pip\n",
    "# %pip install pandas\n",
    "# %pip install sqlalchemy\n",
    "# %time\n",
    "# %pip install tensorflow-gpuKo\n",
    "# %pip install -U matplotlib\n",
    "# %pip install -U scikit-learn\n",
    "# %pip install seaborn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sqlalchemy import create_engine as cg\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import r2_score\n",
    "from math import sqrt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import Sequential, layers, callbacks\n",
    "from keras.layers import Dense, LSTM, Dropout, GRU, Bidirectional\n",
    "\n",
    "# from matplotlib import pyplot as plt\n",
    "# from sklearn.ensemble import IsolationForest\n",
    "# import datetime\n",
    "# from datetime import datetime\n",
    "# import random as rd\n",
    "# import seaborn as sns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Configure Cloud Database Access__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Create cloud DB Access Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "H01_Cloud_DB_Engine = cg(\"postgresql://rbm:M2021739@210.123.42.194:1996/Centralized_DB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Cloud DB SQL query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One Month =\n",
      "2592000\n"
     ]
    }
   ],
   "source": [
    "print('One Month =')\n",
    "print(30*24*60*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SQLquery = ''' SELECT * FROM public.\"H01-ECD\" ORDER BY dt DESC LIMIT 2592000 '''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Data Acquisition & Processing__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Get Last month data from Cloud DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_h01_last_month = pd.read_sql_query(SQLquery, H01_Cloud_DB_Engine)\n",
    "# df_h01_last_month"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __User Defined Functions__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">__F01: Scaling & Splitting Data__ (_Test&Train)___, Saving Model__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaling_splitting_data(dataFrame, fileName, ttRatio=0.80):\n",
    "    trainSize = int(len(dataFrame)*ttRatio)\n",
    "    trainData = dataFrame.iloc[:trainSize]\n",
    "    testData = dataFrame.iloc[trainSize:]\n",
    "    # Train Model\n",
    "    scalerModel = MinMaxScaler().fit(dataFrame)\n",
    "    # Save Model\n",
    "    pickle.dump(scalerModel, open(fileName, 'wb'))\n",
    "    trainData_scaled = scalerModel.transform(trainData)\n",
    "    testData_scaled = scalerModel.transform(testData)\n",
    "    return trainData_scaled, testData_scaled"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">__F02: Creating Array Datasets__ (_Data Preprocessing for Training Tensorflow Models_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_array_dataset(dataFrame, lookBack=1800, horizon=1):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(dataFrame)-lookBack-horizon+1):\n",
    "        Xs.append(dataFrame[i            :i+lookBack        ])\n",
    "        ys.append(dataFrame[i+lookBack   :i+lookBack+horizon])\n",
    "    return np.array(Xs), np.array(ys)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">__F03: Define LSTM Model__ (_Set Hyper-parameters_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_LSTM_model(inputSize, outSize):\n",
    "    # Configure LSTM Model\n",
    "    model = Sequential()\n",
    "    # Input layer\n",
    "    # model.add(LSTM(64, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "    model.add(LSTM(64, return_sequences=True, input_shape=(inputSize, outSize)))\n",
    "    model.add(Dropout(0.2))\n",
    "    # Hidden layer\n",
    "    model.add(LSTM(32))\n",
    "    model.add(Dropout(0.1))\n",
    "    # Output layer\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    print(model.summary())\n",
    "\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">__F04: Develop LSTM Model__ (_Train, Evaluate & Saving Model_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def develop_LSTM_model(model, X_train, y_train, X_test, y_test, fileName, epochSize=10, batchSize=4096):\n",
    "    # Train LSTM Model\n",
    "    early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20)\n",
    "    history    = model.fit(X_train, y_train, epochs=epochSize, batch_size=batchSize, validation_data=(X_test, y_test), verbose=1, shuffle=False, callbacks=[early_stop])\n",
    "    print(history)\n",
    "    print('LSTM Model has been Trained.')\n",
    "\n",
    "    # Evaluating trained LSTM Model\n",
    "    y_pred=model.predict(X_test)\n",
    "    mse=mean_squared_error(y_pred, np.squeeze(y_test))\n",
    "    mae=mean_absolute_error(y_pred,np.squeeze(y_test))\n",
    "    mape=mean_absolute_percentage_error(y_pred, np.squeeze(y_test))\n",
    "    r2=r2_score(y_pred,np.squeeze(y_test))\n",
    "    rmse = sqrt(mean_squared_error(y_pred, np.squeeze(y_test)))\n",
    "    print('MSE:  {:.4f}'.format(mse))\n",
    "    print('MAE:  {:.4f}'.format(mae))\n",
    "    print('RMSE: {:.4f}'.format(rmse))\n",
    "    print('MAPE: {:.4f}'.format(mape))\n",
    "    print('r2:   {:.4f}'.format(r2))\n",
    "\n",
    "    # Saving LSTM Model\n",
    "    model.save(fileName)\n",
    "    print('LSTM Model has been Saved.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">__A01: Train Invididual DL Model__ (_Scale, Split, Train, Evaluate & Saving Model_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train_Individual_DL_Model(dataFrame, dataSelect, saveScaler, saveLSTM, testSize, inputSize, outSize, epochSize, batchSize):\n",
    "    # Extract Heterogeneous Data\n",
    "    df_individual = pd.DataFrame(dataFrame.filter([dataSelect], axis=1).values, columns=[dataSelect])\n",
    "    # Function#01\n",
    "    train_scaled, test_scaled = scaling_splitting_data(dataFrame=df_individual, ttRatio=testSize, fileName=saveScaler)\n",
    "    print(train_scaled.shape, test_scaled.shape)\n",
    "    # Function#02\n",
    "    X_train, y_train = create_array_dataset(train_scaled, lookBack=inputSize, horizon=outSize)\n",
    "    X_test, y_test   = create_array_dataset(test_scaled,  lookBack=inputSize, horizon=outSize)\n",
    "    print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "    # Function#03\n",
    "    LSTM_model = define_LSTM_model(inputSize=inputSize, outSize=outSize)\n",
    "    # Function#04\n",
    "    develop_LSTM_model(model=LSTM_model, X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test, fileName=saveLSTM)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Train Individual DL Models__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> House#01: Water Dispenser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2073600, 1) (518400, 1)\n",
      "(2073300, 300, 1) (2073300, 1, 1) (518100, 300, 1) (518100, 1, 1)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 300, 64)           16896     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 300, 64)           0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 32)                12416     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29,345\n",
      "Trainable params: 29,345\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "507/507 [==============================] - 102s 190ms/step - loss: 0.0023 - val_loss: 0.0013\n",
      "Epoch 2/10\n",
      "507/507 [==============================] - 97s 191ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 3/10\n",
      "507/507 [==============================] - 94s 186ms/step - loss: 0.0010 - val_loss: 9.9530e-04\n",
      "Epoch 4/10\n",
      "507/507 [==============================] - 95s 187ms/step - loss: 9.6251e-04 - val_loss: 8.6873e-04\n",
      "Epoch 5/10\n",
      "507/507 [==============================] - 96s 189ms/step - loss: 9.2133e-04 - val_loss: 8.6328e-04\n",
      "Epoch 6/10\n",
      "507/507 [==============================] - 97s 192ms/step - loss: 8.8929e-04 - val_loss: 7.7669e-04\n",
      "Epoch 7/10\n",
      "507/507 [==============================] - 98s 194ms/step - loss: 8.8041e-04 - val_loss: 7.7738e-04\n",
      "Epoch 8/10\n",
      "507/507 [==============================] - 98s 194ms/step - loss: 8.7221e-04 - val_loss: 7.5643e-04\n",
      "Epoch 9/10\n",
      "507/507 [==============================] - 100s 196ms/step - loss: 8.6678e-04 - val_loss: 8.5287e-04\n",
      "Epoch 10/10\n",
      "507/507 [==============================] - 100s 196ms/step - loss: 8.6523e-04 - val_loss: 0.0010\n",
      "<keras.callbacks.History object at 0x000001B34482EE20>\n",
      "LSTM Model has been Trained.\n",
      "16191/16191 [==============================] - 634s 39ms/step\n",
      "MSE:  0.0010\n",
      "MAE:  0.0144\n",
      "RMSE: 0.0317\n",
      "MAPE: 0.6532\n",
      "r2:   0.9689\n",
      "LSTM Model has been Saved.\n"
     ]
    }
   ],
   "source": [
    "Train_Individual_DL_Model(\n",
    "    dataSelect = 'wd_w',\n",
    "    saveScaler = 'TrainedModels/H#01_wd_w_scaler.sav',\n",
    "    saveLSTM   = 'TrainedModels/H#01_wd_w_LSTM.h5',\n",
    "    dataFrame  = df_h01_last_month,\n",
    "    testSize   = 0.80,\n",
    "    inputSize  = 5*60,\n",
    "    outSize    = 1,\n",
    "    epochSize  = 10,\n",
    "    batchSize  = pow(2,12)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> House#01: Refrigerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2073600, 1) (518400, 1)\n",
      "(2073300, 300, 1) (2073300, 1, 1) (518100, 300, 1) (518100, 1, 1)\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 300, 64)           16896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 300, 64)           0         \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 32)                12416     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29,345\n",
      "Trainable params: 29,345\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "507/507 [==============================] - 101s 193ms/step - loss: 0.0055 - val_loss: 0.0012\n",
      "Epoch 2/10\n",
      "507/507 [==============================] - 98s 194ms/step - loss: 0.0024 - val_loss: 7.6781e-04\n",
      "Epoch 3/10\n",
      "507/507 [==============================] - 99s 195ms/step - loss: 0.0019 - val_loss: 9.1999e-04\n",
      "Epoch 4/10\n",
      "507/507 [==============================] - 98s 194ms/step - loss: 0.0017 - val_loss: 6.2298e-04\n",
      "Epoch 5/10\n",
      "507/507 [==============================] - 98s 193ms/step - loss: 0.0016 - val_loss: 6.4701e-04\n",
      "Epoch 6/10\n",
      "507/507 [==============================] - 98s 194ms/step - loss: 0.0016 - val_loss: 6.6444e-04\n",
      "Epoch 7/10\n",
      "507/507 [==============================] - 98s 193ms/step - loss: 0.0015 - val_loss: 5.6858e-04\n",
      "Epoch 8/10\n",
      "507/507 [==============================] - 99s 194ms/step - loss: 0.0015 - val_loss: 8.3930e-04\n",
      "Epoch 9/10\n",
      "507/507 [==============================] - 98s 194ms/step - loss: 0.0014 - val_loss: 5.3370e-04\n",
      "Epoch 10/10\n",
      "507/507 [==============================] - 98s 194ms/step - loss: 0.0014 - val_loss: 0.0025\n",
      "<keras.callbacks.History object at 0x000001B4138516A0>\n",
      "LSTM Model has been Trained.\n",
      "16191/16191 [==============================] - 619s 38ms/step\n",
      "MSE:  0.0025\n",
      "MAE:  0.0284\n",
      "RMSE: 0.0504\n",
      "MAPE: 0.7770\n",
      "r2:   0.9774\n",
      "LSTM Model has been Saved.\n"
     ]
    }
   ],
   "source": [
    "Train_Individual_DL_Model(\n",
    "    dataSelect = 'rf_w',\n",
    "    saveScaler = 'TrainedModels/H#01_rf_w_scaler.sav',\n",
    "    saveLSTM   = 'TrainedModels/H#01_rf_w_LSTM.h5',\n",
    "    dataFrame  = df_h01_last_month,\n",
    "    testSize   = 0.80,\n",
    "    inputSize  = 5*60,\n",
    "    outSize    = 1,\n",
    "    epochSize  = 10,\n",
    "    batchSize  = pow(2,12)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> House#01: Air Conditioner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2073600, 1) (518400, 1)\n",
      "(2073300, 300, 1) (2073300, 1, 1) (518100, 300, 1) (518100, 1, 1)\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_4 (LSTM)               (None, 300, 64)           16896     \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 300, 64)           0         \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 32)                12416     \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29,345\n",
      "Trainable params: 29,345\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "507/507 [==============================] - 101s 192ms/step - loss: 0.0015 - val_loss: 8.0167e-05\n",
      "Epoch 2/10\n",
      "507/507 [==============================] - 95s 188ms/step - loss: 3.3304e-04 - val_loss: 7.9591e-05\n",
      "Epoch 3/10\n",
      "507/507 [==============================] - 95s 188ms/step - loss: 3.3730e-04 - val_loss: 7.0659e-05\n",
      "Epoch 4/10\n",
      "507/507 [==============================] - 97s 192ms/step - loss: 2.0714e-04 - val_loss: 4.6467e-05\n",
      "Epoch 5/10\n",
      "507/507 [==============================] - 95s 188ms/step - loss: 1.8064e-04 - val_loss: 4.0345e-05\n",
      "Epoch 6/10\n",
      "507/507 [==============================] - 96s 189ms/step - loss: 1.8860e-04 - val_loss: 3.7857e-05\n",
      "Epoch 7/10\n",
      "507/507 [==============================] - 95s 188ms/step - loss: 1.6986e-04 - val_loss: 3.4068e-05\n",
      "Epoch 8/10\n",
      "507/507 [==============================] - 97s 192ms/step - loss: 1.5833e-04 - val_loss: 3.6326e-05\n",
      "Epoch 9/10\n",
      "507/507 [==============================] - 99s 196ms/step - loss: 1.5259e-04 - val_loss: 3.0763e-05\n",
      "Epoch 10/10\n",
      "507/507 [==============================] - 101s 199ms/step - loss: 2.4056e-04 - val_loss: 3.0448e-05\n",
      "<keras.callbacks.History object at 0x000001B436994760>\n",
      "LSTM Model has been Trained.\n",
      "16191/16191 [==============================] - 621s 38ms/step\n",
      "MSE:  0.0000\n",
      "MAE:  0.0018\n",
      "RMSE: 0.0055\n",
      "MAPE: 0.2277\n",
      "r2:   0.9968\n",
      "LSTM Model has been Saved.\n"
     ]
    }
   ],
   "source": [
    "Train_Individual_DL_Model(\n",
    "    dataSelect = 'ac_w',\n",
    "    saveScaler = 'TrainedModels/H#01_ac_w_scaler.sav',\n",
    "    saveLSTM   = 'TrainedModels/H#01_ac_w_LSTM.h5',\n",
    "    dataFrame  = df_h01_last_month,\n",
    "    testSize   = 0.80,\n",
    "    inputSize  = 5*60,\n",
    "    outSize    = 1,\n",
    "    epochSize  = 10,\n",
    "    batchSize  = pow(2,12)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> House#01: Room Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2073600, 1) (518400, 1)\n",
      "(2073300, 300, 1) (2073300, 1, 1) (518100, 300, 1) (518100, 1, 1)\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_6 (LSTM)               (None, 300, 64)           16896     \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 300, 64)           0         \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               (None, 32)                12416     \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29,345\n",
      "Trainable params: 29,345\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "507/507 [==============================] - 100s 191ms/step - loss: 0.0095 - val_loss: 0.0416\n",
      "Epoch 2/10\n",
      "507/507 [==============================] - 97s 191ms/step - loss: 0.0029 - val_loss: 0.0039\n",
      "Epoch 3/10\n",
      "507/507 [==============================] - 96s 190ms/step - loss: 0.0026 - val_loss: 0.0040\n",
      "Epoch 4/10\n",
      "507/507 [==============================] - 94s 186ms/step - loss: 0.0032 - val_loss: 3.7173e-04\n",
      "Epoch 5/10\n",
      "507/507 [==============================] - 97s 191ms/step - loss: 0.0028 - val_loss: 3.4216e-04\n",
      "Epoch 6/10\n",
      "507/507 [==============================] - 95s 187ms/step - loss: 0.0025 - val_loss: 4.3853e-04\n",
      "Epoch 7/10\n",
      "507/507 [==============================] - 95s 188ms/step - loss: 0.0023 - val_loss: 4.3785e-04\n",
      "Epoch 8/10\n",
      "507/507 [==============================] - 95s 188ms/step - loss: 0.0022 - val_loss: 4.0116e-04\n",
      "Epoch 9/10\n",
      "507/507 [==============================] - 96s 188ms/step - loss: 0.0020 - val_loss: 3.9290e-04\n",
      "Epoch 10/10\n",
      "507/507 [==============================] - 94s 186ms/step - loss: 0.0019 - val_loss: 3.3088e-04\n",
      "<keras.callbacks.History object at 0x000001B3B004DD30>\n",
      "LSTM Model has been Trained.\n",
      "16191/16191 [==============================] - 625s 39ms/step\n",
      "MSE:  0.0003\n",
      "MAE:  0.0144\n",
      "RMSE: 0.0182\n",
      "MAPE: 0.0181\n",
      "r2:   -1.1337\n",
      "LSTM Model has been Saved.\n"
     ]
    }
   ],
   "source": [
    "Train_Individual_DL_Model(\n",
    "    dataSelect = 'temp',\n",
    "    saveScaler = 'TrainedModels/H#01_temp_scaler.sav',\n",
    "    saveLSTM   = 'TrainedModels/H#01_temp_LSTM.h5',\n",
    "    dataFrame  = df_h01_last_month,\n",
    "    testSize   = 0.80,\n",
    "    inputSize  = 5*60,\n",
    "    outSize    = 1,\n",
    "    epochSize  = 10,\n",
    "    batchSize  = pow(2,12)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> House#01: Room Humidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2073600, 1) (518400, 1)\n",
      "(2073300, 300, 1) (2073300, 1, 1) (518100, 300, 1) (518100, 1, 1)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 300, 64)           16896     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 300, 64)           0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 32)                12416     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29,345\n",
      "Trainable params: 29,345\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "507/507 [==============================] - 101s 188ms/step - loss: 0.0061 - val_loss: 0.0351\n",
      "Epoch 2/10\n",
      "507/507 [==============================] - 94s 185ms/step - loss: 0.0016 - val_loss: 0.0086\n",
      "Epoch 3/10\n",
      "507/507 [==============================] - 93s 184ms/step - loss: 0.0012 - val_loss: 0.0025\n",
      "Epoch 4/10\n",
      "507/507 [==============================] - 93s 183ms/step - loss: 9.7308e-04 - val_loss: 0.0036\n",
      "Epoch 5/10\n",
      "507/507 [==============================] - 93s 183ms/step - loss: 9.2492e-04 - val_loss: 0.0026\n",
      "Epoch 6/10\n",
      "507/507 [==============================] - 92s 182ms/step - loss: 8.9973e-04 - val_loss: 0.0029\n",
      "Epoch 7/10\n",
      "507/507 [==============================] - 93s 183ms/step - loss: 9.9959e-04 - val_loss: 0.0034\n",
      "Epoch 8/10\n",
      "507/507 [==============================] - 92s 182ms/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 9/10\n",
      "507/507 [==============================] - 93s 183ms/step - loss: 0.0018 - val_loss: 0.0046\n",
      "Epoch 10/10\n",
      "507/507 [==============================] - 93s 184ms/step - loss: 0.0019 - val_loss: 0.0050\n",
      "<keras.callbacks.History object at 0x0000021600641E20>\n",
      "LSTM Model has been Trained.\n",
      "16191/16191 [==============================] - 526s 32ms/step\n",
      "MSE:  0.0050\n",
      "MAE:  0.0570\n",
      "RMSE: 0.0710\n",
      "MAPE: 0.0799\n",
      "r2:   -44.1843\n",
      "LSTM Model has been Saved.\n"
     ]
    }
   ],
   "source": [
    "Train_Individual_DL_Model(\n",
    "    dataSelect = 'humd',\n",
    "    saveScaler = 'TrainedModels/H#01_humd_scaler.sav',\n",
    "    saveLSTM   = 'TrainedModels/H#01_humd_LSTM.h5',\n",
    "    dataFrame  = df_h01_last_month,\n",
    "    testSize   = 0.80,\n",
    "    inputSize  = 5*60,\n",
    "    outSize    = 1,\n",
    "    epochSize  = 10,\n",
    "    batchSize  = pow(2,12)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5421946c93a71ddde79accc46960a20bd7d0ccf9893846e626a623a8d2bc626a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
